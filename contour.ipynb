{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import cv2\n",
    "from mrcnn.visualize import display_instances\n",
    "import matplotlib.pyplot as plt\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "import shutil\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a folder and copy images to train, test and validate folder\n",
    "def create_folder(folder_name):\n",
    "    try:\n",
    "        if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' + folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images ...\n",
      "Number of crack images:  6541\n",
      "Number of spall images:  8577\n",
      "Number of crack images:  3925\n",
      "Number of spall images:  5145\n"
     ]
    }
   ],
   "source": [
    "# function to train, test and validate \n",
    "def train_test_validate_split(dataset, train_percent=.6, validate_percent=.2, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(dataset.shape[0])\n",
    "    m = dataset.shape[0]\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = dataset[perm[:train_end]]\n",
    "    validate = dataset[perm[train_end:validate_end]]\n",
    "    test = dataset[perm[validate_end:]]\n",
    "    return train, validate, test\n",
    "\n",
    "\n",
    "print(\"Loading images ...\")\n",
    "# load the images\n",
    "crack_images = os.listdir(\"dataset/crack/accepted\")\n",
    "spall_images = os.listdir(\"dataset/spall/accepted\")\n",
    "print(\"Number of crack images: \", len(crack_images))\n",
    "print(\"Number of spall images: \", len(spall_images))\n",
    "\n",
    "\n",
    "# if the images are not in train, test and validate folder, then copy them\n",
    "if not os.path.exists(\"dataset/crack/accepted/train\"):\n",
    "    print(\"Copying images to train, test and validate folder ...\")\n",
    "    # create a folder to store the images\n",
    "    crack_train = create_folder(\"dataset/crack/accepted/train\")\n",
    "    crack_validate = create_folder(\"dataset/crack/accepted/validate\")\n",
    "    crack_test = create_folder(\"dataset/crack/accepted/test\")\n",
    "    spall_train = create_folder(\"dataset/spall/accepted/train\")\n",
    "    spall_validate = create_folder(\"dataset/spall/accepted/validate\")\n",
    "    spall_test = create_folder(\"dataset/spall/accepted/test\")\n",
    "\n",
    "    # if no images in train, test and validate folder then copy the images\n",
    "    if len(os.listdir(\"dataset/crack/accepted/train\")) == 0:    \n",
    "        # copy images to train, test and validate folder\n",
    "        for i in range(len(crack_images)):\n",
    "            if i < 0.6 * len(crack_images):\n",
    "                shutil.copy(\"dataset/crack/accepted/\" + crack_images[i], \"dataset/crack/accepted/train\")\n",
    "            elif i < 0.8 * len(crack_images):\n",
    "                shutil.copy(\"dataset/crack/accepted/\" + crack_images[i], \"dataset/crack/accepted/validate\")\n",
    "            else:\n",
    "                shutil.copy(\"dataset/crack/accepted/\" + crack_images[i], \"dataset/crack/accepted/test\")\n",
    "\n",
    "        for i in range(len(spall_images)):\n",
    "            if i < 0.6 * len(spall_images):\n",
    "                shutil.copy(\"dataset/spall/accepted/\" + spall_images[i], \"dataset/spall/accepted/train\")\n",
    "            elif i < 0.8 * len(spall_images):\n",
    "                shutil.copy(\"dataset/spall/accepted/\" + spall_images[i], \"dataset/spall/accepted/validate\")\n",
    "            else:\n",
    "                shutil.copy(\"dataset/spall/accepted/\" + spall_images[i], \"dataset/spall/accepted/test\")\n",
    "\n",
    "        print(\"Copying images to train, test and validate folder completed\")\n",
    "\n",
    "    else:\n",
    "        print(\"Images already in train, test and validate folder\")\n",
    "        \n",
    "# load the images\n",
    "crack_train_images = os.listdir(\"dataset/crack/accepted/train\")\n",
    "spall_train_images = os.listdir(\"dataset/spall/accepted/train\")\n",
    "print(\"Number of crack images: \", len(crack_train_images))\n",
    "print(\"Number of spall images: \", len(spall_train_images))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for extracting edges and contours from an image\n",
    "def get_contours(image):\n",
    "    # convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # apply gaussian blur\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    # apply canny edge detection\n",
    "    canny = cv2.Canny(blur, 50, 150)\n",
    "    # apply dilation\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    dilated = cv2.dilate(canny, kernel, iterations=1)\n",
    "    # apply erosion\n",
    "    eroded = cv2.erode(dilated, kernel, iterations=1)\n",
    "    # find contours\n",
    "    contours, hierarchy = cv2.findContours(eroded, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "# function for drawing contours on an image\n",
    "def draw_contours(image, contours):\n",
    "    # draw contours on a copy of the image\n",
    "    image_copy = np.copy(image)\n",
    "    image_copy = cv2.drawContours(image_copy, contours, -1, (0, 255, 0), 3)\n",
    "    return image_copy\n",
    "\n",
    "# function for sorting contours from left to right\n",
    "def x_cord_contour(contours):\n",
    "    # return the x coordinate for the contour centroid\n",
    "    if cv2.contourArea(contours) > 10:\n",
    "        M = cv2.moments(contours)\n",
    "        return (int(M['m10']/M['m00']))\n",
    "\n",
    "# function for sorting contours from top to bottom\n",
    "def label_contour_center(image, c):\n",
    "    # place a red circle on the centers of contours\n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    # draw the countour number on the image\n",
    "    cv2.circle(image, (cx, cy), 10, (0, 0, 255), -1)\n",
    "    return image\n",
    "\n",
    "# function for creating a mask\n",
    "def make_mask(image, contour):\n",
    "    # fill contour\n",
    "    mask = np.zeros_like(image)\n",
    "    cv2.drawContours(mask, [contour], -1, 255, -1)\n",
    "    # now crop\n",
    "    (x, y) = np.where(mask == 255)\n",
    "    (topx, topy) = (np.min(x), np.min(y))\n",
    "    (bottomx, bottomy) = (np.max(x), np.max(y))\n",
    "    cropped = image[topx:bottomx+1, topy:bottomy+1]\n",
    "    return cropped\n",
    "\n",
    "\n",
    "# function for sorting contours from top to bottom\n",
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "    reverse = False\n",
    "    i = 0\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "    key=lambda b:b[1][i], reverse=reverse))\n",
    "    return (cnts, boundingBoxes)\n",
    "\n",
    "\n",
    "\n",
    "# function for displaying images\n",
    "def display(img, cmap='gray'):\n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ET\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# function to create annotation for images in VGG Image Annotator format\n",
    "def create_annotation(image, contour, image_name):\n",
    "    # get the image height and width\n",
    "    height, width = image.shape[:2]\n",
    "    # create the xml file\n",
    "    annotation = ET.Element(\"annotation\")\n",
    "    ET.SubElement(annotation, \"folder\").text = \"images\"\n",
    "    ET.SubElement(annotation, \"filename\").text = image_name\n",
    "    ET.SubElement(annotation, \"path\").text = \"images/\" + image_name\n",
    "    source = ET.SubElement(annotation, \"source\")\n",
    "    ET.SubElement(source, \"database\").text = \"Unknown\"\n",
    "    size = ET.SubElement(annotation, \"size\")\n",
    "    ET.SubElement(size, \"width\").text = str(width)\n",
    "    ET.SubElement(size, \"height\").text = str(height)\n",
    "    ET.SubElement(size, \"depth\").text = \"3\"\n",
    "    ET.SubElement(annotation, \"segmented\").text = \"0\"\n",
    "    # create the object\n",
    "    object = ET.SubElement(annotation, \"object\")\n",
    "    ET.SubElement(object, \"name\").text = \"crack\"\n",
    "    ET.SubElement(object, \"pose\").text = \"Unspecified\"\n",
    "    ET.SubElement(object, \"truncated\").text = \"0\"\n",
    "    ET.SubElement(object, \"difficult\").text = \"0\"\n",
    "    bndbox = ET.SubElement(object, \"bndbox\")\n",
    "    # get the bounding box coordinates\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    ET.SubElement(bndbox, \"xmin\").text = str(x)\n",
    "    ET.SubElement(bndbox, \"ymin\").text = str(y)\n",
    "    ET.SubElement(bndbox, \"xmax\").text = str(x + w)\n",
    "    ET.SubElement(bndbox, \"ymax\").text = str(y + h)\n",
    "    # create a new XML file with the results\n",
    "    mydata = ET.tostring(annotation)\n",
    "    # \"via_project.json\" for VGG Image Annotator\n",
    "    folder_name = [crack, spall]\n",
    "    for folder in folder_name:\n",
    "        if folder == crack:\n",
    "            mydata = ET.tostring(annotation)\n",
    "            myfile = open(\"dataset/crack/accepted/train/annotations/\" + image_name[:-4] + \".xml\", \"wb\")\n",
    "            myfile.write(mydata)\n",
    "        elif folder == spall:\n",
    "            mydata = ET.tostring(annotation)\n",
    "            myfile = open(\"dataset/spall/accepted/train/annotations/\" + image_name[:-4] + \".xml\", \"wb\")\n",
    "            myfile.write(mydata)\n",
    "    \n",
    "    return mydata    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to annotate the images in train and create \"via_project.json\" for all images in train\n",
    "# get the images in train from crack and spall\n",
    "crack_images = os.listdir(\"dataset/crack/accepted/train\")\n",
    "spall_images = os.listdir(\"dataset/spall/accepted/train\")\n",
    "\n",
    "def annotate_images(dataset):\n",
    "    # get the images in train from crack and spall\n",
    "    for image_name in dataset:\n",
    "        # read the image\n",
    "        image = cv2.imread(\"dataset/crack/accepted/train/\" + image_name)\n",
    "        # convert to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # blur the image\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        # apply canny edge detection\n",
    "        canny = cv2.Canny(blurred, 50, 150)\n",
    "        # find contours\n",
    "        contours, hierarchy = cv2.findContours(canny, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # sort contours from left to right\n",
    "        sorted_contours = sorted(contours, key=x_cord_contour, reverse=False)\n",
    "        # create a copy of the image\n",
    "        image_copy = np.copy(image)\n",
    "        # draw contours on the image\n",
    "        image_copy = draw_contours(image_copy, sorted_contours)\n",
    "        # label the center of the contours\n",
    "        image_copy = label_contour_center(image_copy, sorted_contours)\n",
    "        # create a mask\n",
    "        mask = make_mask(image, sorted_contours[0])\n",
    "        # create annotation\n",
    "        create_annotation(image, sorted_contours[0], image_name)\n",
    "        # display the image\n",
    "        display(image_copy)\n",
    "        # display the mask\n",
    "        display(mask)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[203], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# annotate the images in train\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m annotate_images(crack_images)\n\u001b[0;32m      3\u001b[0m annotate_images(spall_images)\n",
      "Cell \u001b[1;32mIn[202], line 20\u001b[0m, in \u001b[0;36mannotate_images\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     18\u001b[0m contours, hierarchy \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mfindContours(canny, cv2\u001b[39m.\u001b[39mRETR_TREE, cv2\u001b[39m.\u001b[39mCHAIN_APPROX_SIMPLE)\n\u001b[0;32m     19\u001b[0m \u001b[39m# sort contours from left to right\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m sorted_contours \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39;49m(contours, key\u001b[39m=\u001b[39;49mx_cord_contour, reverse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     21\u001b[0m \u001b[39m# create a copy of the image\u001b[39;00m\n\u001b[0;32m     22\u001b[0m image_copy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(image)\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# annotate the images in train\n",
    "annotate_images(crack_images)\n",
    "annotate_images(spall_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# function to create annotations for each image and save it as a json file in the annotation folder\n",
    "def create_annotation_crack(image_name, image_path, image, contours):\n",
    "    # create a dictionary\n",
    "    data = {}\n",
    "    data['imagePath'] = image_path\n",
    "    data['imageData'] = None\n",
    "    data['imageHeight'] = image.shape[0]\n",
    "    data['imageWidth'] = image.shape[1]\n",
    "    data['shapes'] = []\n",
    "    for i in range(len(contours)):\n",
    "        shape = {}\n",
    "        shape['label'] = 'crack'\n",
    "        shape['points'] = []\n",
    "        shape['group_id'] = None\n",
    "        shape['shape_type'] = 'polygon'\n",
    "        shape['flags'] = {}\n",
    "        for j in range(len(contours[i])):\n",
    "            shape['points'].append([int(contours[i][j][0][0]), int(contours[i][j][0][1])])\n",
    "        data['shapes'].append(shape)\n",
    "    # save the dictionary as a json file\n",
    "    with open('dataset/crack/accepted/annotation/'+image_name+'.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "\n",
    "# function to create annotations for each image and save it as a json file in the annotation folder\n",
    "def create_annotation_spall(image_name, image_path, image, contours):\n",
    "    # create a dictionary\n",
    "    data = {}\n",
    "    data['imagePath'] = image_path\n",
    "    data['imageData'] = None\n",
    "    data['imageHeight'] = image.shape[0]\n",
    "    data['imageWidth'] = image.shape[1]\n",
    "    data['shapes'] = []\n",
    "    for i in range(len(contours)):\n",
    "        shape = {}\n",
    "        shape['label'] = 'spall'\n",
    "        shape['points'] = []\n",
    "        shape['group_id'] = None\n",
    "        shape['shape_type'] = 'polygon'\n",
    "        shape['flags'] = {}\n",
    "        for j in range(len(contours[i])):\n",
    "            shape['points'].append([int(contours[i][j][0][0]), int(contours[i][j][0][1])])\n",
    "        data['shapes'].append(shape)\n",
    "    # save the dictionary as a json file\n",
    "    with open('dataset/spall/accepted/annotation/'+image_name+'.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\Downloads\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.9\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           custom\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                131\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "print(ROOT_DIR)\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "\n",
    "# Path to trained weights file\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "class CustomConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"custom\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + custom\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 131\n",
    "\n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "\n",
    "config = CustomConfig()\n",
    "config.display()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom dataset\n",
    "class CustomDataset(utils.Dataset):\n",
    "        def load_custom(self, dataset_dir, subset):\n",
    "            \"\"\"Load a subset of the Custom dataset.\n",
    "            dataset_dir: Root directory of the dataset.\n",
    "            subset: Subset to load: train or val\n",
    "            \"\"\"\n",
    "            # Add classes. We have only one class to add.\n",
    "            self.add_class(\"custom\", 1, \"crack\")\n",
    "            self.add_class(\"custom\", 2, \"spall\")\n",
    "    \n",
    "            # Train or validation dataset?\n",
    "            assert subset in [\"train\", \"val\"]\n",
    "            dataset_dir = os.path.join(dataset_dir, subset)\n",
    "    \n",
    "            # Load annotations\n",
    "            # VGG Image Annotator (up to version 1.6) saves each image in the form:\n",
    "            # { 'filename': '28503151_5b5b7ec140_b.jpg',\n",
    "            #   'regions': {\n",
    "            #       '0': {\n",
    "            #           'region_attributes': {},\n",
    "            #           'shape_attributes': {\n",
    "            #               'all_points_x': [...],\n",
    "            #               'all_points_y': [...],\n",
    "            #               'name': 'polygon'}},\n",
    "            #       ... more regions ...\n",
    "            #   },\n",
    "            #   'size': 100202\n",
    "            # }\n",
    "            # We mostly care about the x and y coordinates of each region\n",
    "            \n",
    "            # Load annotations from json file for each image in the \n",
    "            # crack/accepted/annotation and spall/accepted/annotation\n",
    "            \n",
    "            # function to load annotations for crack and spall images in accepted folder\n",
    "            def load_annotations(dataset_dir, subset):\n",
    "                # Add images\n",
    "                for image_name in os.listdir(dataset_dir):\n",
    "                    if image_name.endswith('.json'):\n",
    "                        annotations = json.load(open(os.path.join(dataset_dir, image_name)))\n",
    "                        annotations = list(annotations.values())\n",
    "                        # some images don't have any annotations. Skip them.\n",
    "                        annotations = [a for a in annotations if a['regions']]\n",
    "                        for a in annotations:\n",
    "                            polygons = [r['shape_attributes'] for r in a['regions'].values()]\n",
    "                            name_dict = [r['region_attributes'] for r in a['regions'].values()]\n",
    "                            name = [list(n.keys())[0] for n in name_dict]\n",
    "                            objects = [s['name'] for s in polygons]\n",
    "                            name_dict = dict(zip(objects, name))\n",
    "                            num_ids = [1 if n == 'crack' else 2 for n in name]\n",
    "                            num_ids = [int(n) for n in num_ids]\n",
    "                            name_dict = {1: 'crack', 2: 'spall'}\n",
    "                            print(name_dict)\n",
    "                            # load_mask() needs the image size to convert polygons\n",
    "                            # to masks. Unfortunately, VIA doesn't include it in\n",
    "                            # JSON, so we must read the image. This is only managable\n",
    "                            # since the dataset is tiny.\n",
    "                            image_path = os.path.join(dataset_dir, a['filename'])\n",
    "                            image = skimage.io.imread(image_path)\n",
    "                            height, width = image.shape[:2]\n",
    "    \n",
    "                            self.add_image(\n",
    "                                \"custom\",\n",
    "                                image_id=a['filename'],  # use file name as a unique image id\n",
    "                                path=image_path,\n",
    "                                width=width, height=height,\n",
    "                                polygons=polygons,\n",
    "                                num_ids=num_ids,\n",
    "                                name_dict=name_dict)\n",
    "\n",
    "\n",
    "            # load annotations for crack and spall images in accepted folder\n",
    "            load_annotations(dataset_dir, subset)\n",
    "\n",
    "        def load_mask(self, image_id):\n",
    "            \"\"\"Generate instance masks for an image.\n",
    "            Returns:\n",
    "            masks: A bool array of shape [height, width, instance count] with\n",
    "                one mask per instance.\n",
    "            class_ids: a 1D array of\n",
    "            \"\"\"\n",
    "            # If not a custom dataset image, delegate to parent class.\n",
    "            image_info = self.image_info[image_id]\n",
    "            if image_info[\"source\"] != \"custom\":\n",
    "                return super(self.__class__, self).load_mask(image_id)\n",
    "            # Convert polygons to a bitmap mask of shape\n",
    "            # [height, width, instance_count]\n",
    "            info = self.image_info[image_id]\n",
    "            num_ids = info['num_ids']\n",
    "            name_dict = info['name_dict']\n",
    "            mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                            dtype=np.uint8)\n",
    "\n",
    "            for i, p in enumerate(info[\"polygons\"]):\n",
    "                # Get indexes of pixels inside the polygon and set them to 1\n",
    "                rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "                mask[rr, cc, i] = 1\n",
    "\n",
    "            num_ids = np.array(num_ids, dtype=np.int32)\n",
    "            return mask, num_ids\n",
    "\n",
    "        def image_reference(self, image_id):\n",
    "            \"\"\"Return the path of the image.\"\"\"\n",
    "            info = self.image_info[image_id]\n",
    "            if info[\"source\"] == \"custom\":\n",
    "                return info[\"path\"]\n",
    "            else:\n",
    "                super(self.__class__, self).image_reference(image_id)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for the training dataset\n",
    "def train(model):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    # Training dataset.\n",
    "    dataset_train = CustomDataset()\n",
    "    dataset_train.load_custom(args.dataset, \"train\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = CustomDataset()\n",
    "    dataset_val.load_custom(args.dataset, \"val\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    # *** This training schedule is an example. Update to your needs ***\n",
    "    # Since we're using a very small dataset, and starting from\n",
    "    # COCO trained weights, we don't need to train too long. Also,\n",
    "    # no need to train all layers, just the heads should do it.\n",
    "    print(\"Training network heads\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=40,\n",
    "                layers='heads')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Training dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m dataset_train \u001b[39m=\u001b[39m CustomDataset()\n\u001b[1;32m----> 3\u001b[0m dataset_train\u001b[39m.\u001b[39mload_custom(args\u001b[39m.\u001b[39mdataset, \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m dataset_train\u001b[39m.\u001b[39mprepare()\n\u001b[0;32m      7\u001b[0m \u001b[39m# Validation dataset\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "# Training dataset\n",
    "dataset_train = CustomDataset()\n",
    "dataset_train.load_custom(args.dataset, \"train\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = CustomDataset()\n",
    "dataset_val.load_custom(dataset, \"val\")\n",
    "dataset_val.prepare()\n",
    "\n",
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                            model_dir=args.logs)\n",
    "\n",
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_WEIGHTS_PATH, by_name=True,\n",
    "                        exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)\n",
    "\n",
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=30,\n",
    "            layers='heads')\n",
    "\n",
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also\n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=40,\n",
    "            layers=\"all\")\n",
    "\n",
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"model/new_mask_rcnn_shapes.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b88035d43cae4ec9859beb9dd03c579ae603966a787fa161926276b5c98c4160"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
