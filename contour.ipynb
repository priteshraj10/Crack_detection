{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import cv2\n",
    "from mrcnn.visualize import display_instances\n",
    "import matplotlib.pyplot as plt\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for extracting edges and contours from an image\n",
    "def get_contours(image):\n",
    "    # convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # apply gaussian blur\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    # apply canny edge detection\n",
    "    canny = cv2.Canny(blur, 50, 150)\n",
    "    # apply dilation\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    dilated = cv2.dilate(canny, kernel, iterations=1)\n",
    "    # apply erosion\n",
    "    eroded = cv2.erode(dilated, kernel, iterations=1)\n",
    "    # find contours\n",
    "    contours, hierarchy = cv2.findContours(eroded, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "# function for drawing contours on an image\n",
    "def draw_contours(image, contours):\n",
    "    # draw contours on a copy of the image\n",
    "    image_copy = np.copy(image)\n",
    "    image_copy = cv2.drawContours(image_copy, contours, -1, (0, 255, 0), 3)\n",
    "    return image_copy\n",
    "\n",
    "# function for sorting contours from left to right\n",
    "def x_cord_contour(contours):\n",
    "    # return the x coordinate for the contour centroid\n",
    "    if cv2.contourArea(contours) > 10:\n",
    "        M = cv2.moments(contours)\n",
    "        return (int(M['m10']/M['m00']))\n",
    "\n",
    "# function for sorting contours from top to bottom\n",
    "def label_contour_center(image, c):\n",
    "    # place a red circle on the centers of contours\n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    # draw the countour number on the image\n",
    "    cv2.circle(image, (cx, cy), 10, (0, 0, 255), -1)\n",
    "    return image\n",
    "\n",
    "# function for creating a mask\n",
    "def make_mask(image, contour):\n",
    "    # fill contour\n",
    "    mask = np.zeros_like(image)\n",
    "    cv2.drawContours(mask, [contour], -1, 255, -1)\n",
    "    # now crop\n",
    "    (x, y) = np.where(mask == 255)\n",
    "    (topx, topy) = (np.min(x), np.min(y))\n",
    "    (bottomx, bottomy) = (np.max(x), np.max(y))\n",
    "    cropped = image[topx:bottomx+1, topy:bottomy+1]\n",
    "    return cropped\n",
    "\n",
    "\n",
    "# function for sorting contours from top to bottom\n",
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "    reverse = False\n",
    "    i = 0\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "    key=lambda b:b[1][i], reverse=reverse))\n",
    "    return (cnts, boundingBoxes)\n",
    "\n",
    "\n",
    "\n",
    "# function for displaying images\n",
    "def display(img, cmap='gray'):\n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a folder annotation folder inside dataset/crack/accepted/annotation folder\n",
    "def create_folder(folder_name):\n",
    "    try:\n",
    "        if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' + folder_name)\n",
    "\n",
    "create_folder('dataset/crack/accepted/annotation')\n",
    "create_folder('dataset/spall/accepted/annotation')\n",
    "create_folder('dataset/crack/nonAccepted/annotation')\n",
    "create_folder('dataset/spall/nonAccepted/annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create annotations for each image and save it as a json file in the annotation folder\n",
    "def create_annotation_crack(image_name, image_path, image, contours):\n",
    "    # create a dictionary\n",
    "    data = {}\n",
    "    data['imagePath'] = image_path\n",
    "    data['imageData'] = None\n",
    "    data['imageHeight'] = image.shape[0]\n",
    "    data['imageWidth'] = image.shape[1]\n",
    "    data['shapes'] = []\n",
    "    for i in range(len(contours)):\n",
    "        shape = {}\n",
    "        shape['label'] = 'crack'\n",
    "        shape['points'] = []\n",
    "        shape['group_id'] = None\n",
    "        shape['shape_type'] = 'polygon'\n",
    "        shape['flags'] = {}\n",
    "        for j in range(len(contours[i])):\n",
    "            shape['points'].append([int(contours[i][j][0][0]), int(contours[i][j][0][1])])\n",
    "        data['shapes'].append(shape)\n",
    "    # save the dictionary as a json file\n",
    "    with open('dataset/crack/accepted/annotation/'+image_name+'.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "\n",
    "# function to create annotations for each image and save it as a json file in the annotation folder\n",
    "def create_annotation_spall(image_name, image_path, image, contours):\n",
    "    # create a dictionary\n",
    "    data = {}\n",
    "    data['imagePath'] = image_path\n",
    "    data['imageData'] = None\n",
    "    data['imageHeight'] = image.shape[0]\n",
    "    data['imageWidth'] = image.shape[1]\n",
    "    data['shapes'] = []\n",
    "    for i in range(len(contours)):\n",
    "        shape = {}\n",
    "        shape['label'] = 'spall'\n",
    "        shape['points'] = []\n",
    "        shape['group_id'] = None\n",
    "        shape['shape_type'] = 'polygon'\n",
    "        shape['flags'] = {}\n",
    "        for j in range(len(contours[i])):\n",
    "            shape['points'].append([int(contours[i][j][0][0]), int(contours[i][j][0][1])])\n",
    "        data['shapes'].append(shape)\n",
    "    # save the dictionary as a json file\n",
    "    with open('dataset/spall/accepted/annotation/'+image_name+'.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m         image_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdataset/spall/accepted/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mimage_name\n\u001b[0;32m     13\u001b[0m         image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(image_path)\n\u001b[1;32m---> 14\u001b[0m         contours \u001b[39m=\u001b[39m get_contours(image)\n\u001b[0;32m     15\u001b[0m         create_annotation_spall(image_name[:\u001b[39m-\u001b[39m\u001b[39m4\u001b[39m], image_path, image, contours)\n\u001b[0;32m     17\u001b[0m \u001b[39m# read all the images inside the crack/nonAccepeted folder and create annotations for each image and create annotation folder\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[58], line 4\u001b[0m, in \u001b[0;36mget_contours\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_contours\u001b[39m(image):\n\u001b[0;32m      3\u001b[0m     \u001b[39m# convert image to grayscale\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(image, cv2\u001b[39m.\u001b[39;49mCOLOR_RGB2GRAY)\n\u001b[0;32m      5\u001b[0m     \u001b[39m# apply gaussian blur\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     blur \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mGaussianBlur(gray, (\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m), \u001b[39m0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# read all the images inside the crack/accepeted folder and create annotations for each image and create annotation folder\n",
    "for image_name in os.listdir('dataset/crack/accepted'):\n",
    "    if image_name.endswith('.jpg'):\n",
    "        image_path = 'dataset/crack/accepted/'+image_name\n",
    "        image = cv2.imread(image_path)\n",
    "        contours = get_contours(image)\n",
    "        create_annotation_crack(image_name[:-4], image_path, image, contours)\n",
    "\n",
    "# read all the images inside the spall/accepeted folder and create annotations for each image and create annotation folder\n",
    "for image_name in os.listdir('dataset/spall/accepted'):\n",
    "    if image_name.endswith('.jpg'):\n",
    "        image_path = 'dataset/spall/accepted/'+image_name\n",
    "        image = cv2.imread(image_path)\n",
    "        contours = get_contours(image)\n",
    "        create_annotation_spall(image_name[:-4], image_path, image, contours)\n",
    "\n",
    "# read all the images inside the crack/nonAccepeted folder and create annotations for each image and create annotation folder\n",
    "for image_name in os.listdir('dataset/crack/nonAccepted'):\n",
    "    if image_name.endswith('.jpg'):\n",
    "        image_path = 'dataset/crack/nonAccepted/'+image_name\n",
    "        image = cv2.imread(image_path)\n",
    "        contours = get_contours(image)\n",
    "        create_annotation_crack(image_name[:-4], image_path, image, contours)\n",
    "\n",
    "# read all the images inside the spall/nonAccepeted folder and create annotations for each image and create annotation folder\n",
    "for image_name in os.listdir('dataset/spall/nonAccepted'):\n",
    "    if image_name.endswith('.jpg'):\n",
    "        image_path = 'dataset/spall/nonAccepted/'+image_name\n",
    "        image = cv2.imread(image_path)\n",
    "        contours = get_contours(image)\n",
    "        create_annotation_spall(image_name[:-4], image_path, image, contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\Downloads\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.9\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           custom\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                131\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "print(ROOT_DIR)\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "\n",
    "# Path to trained weights file\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "class CustomConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"custom\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + custom\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 131\n",
    "\n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "\n",
    "config = CustomConfig()\n",
    "config.display()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom dataset\n",
    "class CustomDataset(utils.Dataset):\n",
    "        def load_custom(self, dataset_dir, subset):\n",
    "            \"\"\"Load a subset of the Custom dataset.\n",
    "            dataset_dir: Root directory of the dataset.\n",
    "            subset: Subset to load: train or val\n",
    "            \"\"\"\n",
    "            # Add classes. We have only one class to add.\n",
    "            self.add_class(\"custom\", 1, \"crack\")\n",
    "            self.add_class(\"custom\", 2, \"spall\")\n",
    "    \n",
    "            # Train or validation dataset?\n",
    "            assert subset in [\"train\", \"val\"]\n",
    "            dataset_dir = os.path.join(dataset_dir, subset)\n",
    "    \n",
    "            # Load annotations\n",
    "            # VGG Image Annotator (up to version 1.6) saves each image in the form:\n",
    "            # { 'filename': '28503151_5b5b7ec140_b.jpg',\n",
    "            #   'regions': {\n",
    "            #       '0': {\n",
    "            #           'region_attributes': {},\n",
    "            #           'shape_attributes': {\n",
    "            #               'all_points_x': [...],\n",
    "            #               'all_points_y': [...],\n",
    "            #               'name': 'polygon'}},\n",
    "            #       ... more regions ...\n",
    "            #   },\n",
    "            #   'size': 100202\n",
    "            # }\n",
    "            # We mostly care about the x and y coordinates of each region\n",
    "            \n",
    "            # Load annotations from json file for each image in the \n",
    "            # crack/accepted/annotation and spall/accepted/annotation\n",
    "            \n",
    "            # function to load annotations for crack and spall images in accepted folder\n",
    "            def load_annotations(dataset_dir, subset):\n",
    "                # Add images\n",
    "                for image_name in os.listdir(dataset_dir):\n",
    "                    if image_name.endswith('.json'):\n",
    "                        annotations = json.load(open(os.path.join(dataset_dir, image_name)))\n",
    "                        annotations = list(annotations.values())\n",
    "                        # some images don't have any annotations. Skip them.\n",
    "                        annotations = [a for a in annotations if a['regions']]\n",
    "                        for a in annotations:\n",
    "                            polygons = [r['shape_attributes'] for r in a['regions'].values()]\n",
    "                            name_dict = [r['region_attributes'] for r in a['regions'].values()]\n",
    "                            name = [list(n.keys())[0] for n in name_dict]\n",
    "                            objects = [s['name'] for s in polygons]\n",
    "                            name_dict = dict(zip(objects, name))\n",
    "                            num_ids = [1 if n == 'crack' else 2 for n in name]\n",
    "                            num_ids = [int(n) for n in num_ids]\n",
    "                            name_dict = {1: 'crack', 2: 'spall'}\n",
    "                            print(name_dict)\n",
    "                            # load_mask() needs the image size to convert polygons\n",
    "                            # to masks. Unfortunately, VIA doesn't include it in\n",
    "                            # JSON, so we must read the image. This is only managable\n",
    "                            # since the dataset is tiny.\n",
    "                            image_path = os.path.join(dataset_dir, a['filename'])\n",
    "                            image = skimage.io.imread(image_path)\n",
    "                            height, width = image.shape[:2]\n",
    "    \n",
    "                            self.add_image(\n",
    "                                \"custom\",\n",
    "                                image_id=a['filename'],  # use file name as a unique image id\n",
    "                                path=image_path,\n",
    "                                width=width, height=height,\n",
    "                                polygons=polygons,\n",
    "                                num_ids=num_ids,\n",
    "                                name_dict=name_dict)\n",
    "\n",
    "\n",
    "            # load annotations for crack and spall images in accepted folder\n",
    "            load_annotations(dataset_dir, subset)\n",
    "\n",
    "            # Load annotations from json file for each image in the\n",
    "            # crack/nonAccepted/annotation and spall/nonAccepted/annotation\n",
    "\n",
    "        def load_mask(self, image_id):\n",
    "            \"\"\"Generate instance masks for an image.\n",
    "            Returns:\n",
    "            masks: A bool array of shape [height, width, instance count] with\n",
    "                one mask per instance.\n",
    "            class_ids: a 1D array of\n",
    "            \"\"\"\n",
    "            # If not a custom dataset image, delegate to parent class.\n",
    "            image_info = self.image_info[image_id]\n",
    "            if image_info[\"source\"] != \"custom\":\n",
    "                return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "            # Convert polygons to a bitmap mask of shape\n",
    "            # [height, width, instance_count]\n",
    "            info = self.image_info[image_id]\n",
    "            num_ids = info['num_ids']\n",
    "            name_dict = info['name_dict']\n",
    "            mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                            dtype=np.uint8)\n",
    "\n",
    "            for i, p in enumerate(info[\"polygons\"]):\n",
    "                # Get indexes of pixels inside the polygon and set them to 1\n",
    "                rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "                mask[rr, cc, i] = 1\n",
    "\n",
    "            \n",
    "            # Return mask, and array of class IDs of each instance. Since we have\n",
    "            # one class ID only, we return an array of 1s\n",
    "            # Map class names to class IDs.\n",
    "\n",
    "            class_ids = np.array(num_ids, dtype=np.int32)\n",
    "            return mask, class_ids\n",
    "\n",
    "        def image_reference(self, image_id):\n",
    "            \"\"\"Return the path of the image.\"\"\"\n",
    "            info = self.image_info[image_id]\n",
    "            if info[\"source\"] == \"custom\":\n",
    "                return info[\"path\"]\n",
    "            else:\n",
    "                super(self.__class__, self).image_reference(image_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m dataset \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(ROOT_DIR, \u001b[39m\"\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m dataset_train \u001b[39m=\u001b[39m CustomDataset()\n\u001b[1;32m----> 5\u001b[0m dataset_train\u001b[39m.\u001b[39;49mload_custom(dataset, \u001b[39m\"\u001b[39;49m\u001b[39mcrack/accepted\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m dataset_train\u001b[39m.\u001b[39mprepare()\n\u001b[0;32m      9\u001b[0m \u001b[39m# Validation dataset\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[71], line 13\u001b[0m, in \u001b[0;36mCustomDataset.load_custom\u001b[1;34m(self, dataset_dir, subset)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_class(\u001b[39m\"\u001b[39m\u001b[39mcustom\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mspall\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[39m# Train or validation dataset?\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[39massert\u001b[39;00m subset \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     14\u001b[0m dataset_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dataset_dir, subset)\n\u001b[0;32m     16\u001b[0m \u001b[39m# Load annotations\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# VGG Image Annotator (up to version 1.6) saves each image in the form:\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m# { 'filename': '28503151_5b5b7ec140_b.jpg',\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39m# }\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m# We mostly care about the x and y coordinates of each region\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training dataset\n",
    "# set args.dataset to the path of the dataset\n",
    "dataset = os.path.join(ROOT_DIR, \"dataset\")\n",
    "dataset_train = CustomDataset()\n",
    "dataset_train.load_custom(dataset, \"crack/accepted\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = CustomDataset()\n",
    "dataset_val.load_custom(dataset, \"val\")\n",
    "dataset_val.prepare()\n",
    "\n",
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)\n",
    "\n",
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                            model_dir=args.logs)\n",
    "\n",
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_WEIGHTS_PATH, by_name=True,\n",
    "                        exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)\n",
    "\n",
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=30,\n",
    "            layers='heads')\n",
    "\n",
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also\n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=40,\n",
    "            layers=\"all\")\n",
    "\n",
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"model/new_mask_rcnn_shapes.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b88035d43cae4ec9859beb9dd03c579ae603966a787fa161926276b5c98c4160"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
